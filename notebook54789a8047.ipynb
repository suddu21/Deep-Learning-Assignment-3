{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-05-13T10:39:02.956721Z",
     "iopub.status.busy": "2024-05-13T10:39:02.956150Z",
     "iopub.status.idle": "2024-05-13T10:39:07.378012Z",
     "shell.execute_reply": "2024-05-13T10:39:07.376746Z",
     "shell.execute_reply.started": "2024-05-13T10:39:02.956690Z"
    },
    "id": "ys8_6uZsFwpc",
    "outputId": "5dd618fc-5702-4a20-e4a4-e717e1f4a5e7",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n",
      "2.1.2\n",
      "cuda\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "# Print the name of the CUDA device, if available\n",
    "print(torch.device('cuda:0'))\n",
    "# Print the version of the torch library\n",
    "print(torch.__version__)\n",
    "\n",
    "# Create a variable to store the device to be used\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Print the device that will be used\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T10:39:07.381501Z",
     "iopub.status.busy": "2024-05-13T10:39:07.380691Z",
     "iopub.status.idle": "2024-05-13T10:39:10.921236Z",
     "shell.execute_reply": "2024-05-13T10:39:10.920452Z",
     "shell.execute_reply.started": "2024-05-13T10:39:07.381456Z"
    },
    "id": "KPLdU191FxaW",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import pandas as pd\n",
    "import math\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn.functional as F  # Parameterless functions, like (some) activation functions\n",
    "import torchvision.datasets as datasets  # Standard datasets\n",
    "import torchvision.transforms as transforms  # Transformations we can perform on our dataset for augmentation\n",
    "from torch import optim  # For optimizers like SGD, Adam, etc.\n",
    "from torch import nn  # All neural network modules\n",
    "from torch.utils.data import (\n",
    "    DataLoader, random_split\n",
    ")  # Gives easier dataset managment by creating mini batches etc.\n",
    "from tqdm import tqdm  # For nice progress bar!\n",
    "\n",
    "from torchvision.datasets import ImageFolder\n",
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pathlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T10:39:10.922887Z",
     "iopub.status.busy": "2024-05-13T10:39:10.922333Z",
     "iopub.status.idle": "2024-05-13T10:39:10.933075Z",
     "shell.execute_reply": "2024-05-13T10:39:10.932224Z",
     "shell.execute_reply.started": "2024-05-13T10:39:10.922860Z"
    },
    "id": "sbHpQ-qgFzIa",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "  This function sets the random seed for all major Python libraries.\n",
    "\n",
    "  Args:\n",
    "    seed (int): The random seed to use.\n",
    "\n",
    "  \"\"\"\n",
    "def seed_everything(seed=1):\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "seed_everything()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T10:39:10.935852Z",
     "iopub.status.busy": "2024-05-13T10:39:10.935552Z",
     "iopub.status.idle": "2024-05-13T10:39:10.960240Z",
     "shell.execute_reply": "2024-05-13T10:39:10.959267Z",
     "shell.execute_reply.started": "2024-05-13T10:39:10.935820Z"
    },
    "id": "WYH8LazuF1kK",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Data Preprocessing\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "'''\n",
    "Class Vovabulary is used to create vocabulary from the training dataset.\n",
    "'''\n",
    "class Vocabulary:\n",
    "    \"\"\"\n",
    "    Args:\n",
    "      file_path (string): The path to the CSV file containing the training data.\n",
    "      src_lang (string): The name of the source language.\n",
    "      trg_lang (string): The name of the target language.\n",
    "\n",
    "    Raises:\n",
    "      ValueError: If the file_path does not exist.\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, file_path, src_lang, trg_lang):\n",
    "        # Read the CSV file into a Pandas DataFrame.\n",
    "        self.translations = pd.read_csv(file_path, header=None, names=[src_lang, trg_lang])\n",
    "        # It will drop any rows with missing values\n",
    "        self.translations.dropna()\n",
    "        self.src_lang = src_lang\n",
    "        self.trg_lang = trg_lang\n",
    "        # Create a dictionary that maps each character in the source language to an integer index.\n",
    "        self.trg_vocab = {char: i+3 for i, char in enumerate(sorted(list(set(''.join(self.translations[trg_lang].tolist())))))}\n",
    "        # Create a dictionary that maps each character in the target language to an integer index.\n",
    "        self.src_vocab = {char: i+3 for i, char in enumerate(sorted(list(set(''.join(self.translations[src_lang].tolist())))))}\n",
    "        \n",
    "        # Add special tokens to the vocabularies.\n",
    "        self.trg_vocab['<'] = 0\n",
    "        self.src_vocab['<'] = 0\n",
    "\n",
    "        self.trg_vocab['<unk>'] = 2\n",
    "        self.src_vocab['<pad>'] = 1\n",
    "        self.trg_vocab['<pad>'] = 1\n",
    "        \n",
    "        self.src_vocab['<unk>'] = 2\n",
    "        \n",
    "        # Extract the unique characters in the source and target languages\n",
    "        src_chars = sorted(set(''.join(self.translations[src_lang])))\n",
    "        trg_chars = sorted(set(''.join(self.translations[trg_lang])))\n",
    "\n",
    "        # Assign an index to each character in the source and target languages\n",
    "        self.t_char_to_idx = {char: idx+3 for idx, char in enumerate(trg_chars)}\n",
    "        self.t_char_to_idx['<unk>']=2\n",
    "        self.t_idx_to_char = {idx: char for char, idx in self.t_char_to_idx.items()}\n",
    "        \n",
    "        self.s_char_to_idx = {char: idx+3 for idx, char in enumerate(src_chars)}\n",
    "        self.s_char_to_idx['<unk>']=2\n",
    "        self.s_idx_to_char = {idx: char for char, idx in self.s_char_to_idx.items()}\n",
    "        \n",
    "      \n",
    "\n",
    "\n",
    "    def get(self):\n",
    "         # This function returns the source and target vocabularies, as well as the dictionaries that map characters to integer indexes and vice versa.\n",
    "        return self.src_vocab,self.trg_vocab,self.t_char_to_idx,self.t_idx_to_char,self.s_char_to_idx,self.s_idx_to_char\n",
    "        \n",
    "\n",
    "\n",
    "class TransliterationDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "      file_path (string): The path to the CSV file containing the training data.\n",
    "      src_lang (string): The name of the source language.\n",
    "      trg_lang (string): The name of the target language.\n",
    "      src_vocab (Vocabulary): The vocabulary for the source language.\n",
    "      trg_vocab (Vocabulary): The vocabulary for the target language.\n",
    "\n",
    "    Raises:\n",
    "      ValueError: If the file_path does not exist.\n",
    "\n",
    "    \"\"\"\n",
    "    def __init__(self, file_path, src_lang, trg_lang,src_vocab,trg_vocab,t_char_to_idx):\n",
    "        self.translations = pd.read_csv(file_path, header=None, names=[src_lang, trg_lang])\n",
    "        self.translations.dropna()\n",
    "    \n",
    "        self.src_lang = src_lang\n",
    "        self.t_char_to_idx = t_char_to_idx\n",
    "        self.trg_lang = trg_lang\n",
    "        self.src_vocab = src_vocab\n",
    "        self.trg_vocab = trg_vocab\n",
    "        self.max_src_len = max([len(word) for word in self.translations[src_lang].tolist()])+1\n",
    "        #print(\"max src len\",self.max_src_len)\n",
    "        self.max_trg_len = max([len(word) for word in self.translations[trg_lang].tolist()])+1\n",
    "        #print(\"max trg len\",self.max_trg_len)\n",
    "    def __len__(self):\n",
    "        return len(self.translations)\n",
    "\n",
    "    def target_to_one_hot(self, target_word, char_to_idx):\n",
    "        num_trg_chars = len(char_to_idx)\n",
    "        max_target_len = self.max_trg_len\n",
    "        # Create a tensor of zeros for the one-hot encoding\n",
    "        one_hot = torch.zeros((max_target_len, num_trg_chars))\n",
    "        # Encode each character in the target word as a one-hot vector\n",
    "        for i, char in enumerate(target_word):\n",
    "            #print(i,char)\n",
    "            char_idx = char_to_idx[char if char in  char_to_idx else '<unk>']\n",
    "            #print(char_idx)\n",
    "            one_hot[i][char_idx] = 1\n",
    "        return one_hot\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        src_word = self.translations.iloc[idx][self.src_lang]\n",
    "        trg_word = self.translations.iloc[idx][self.trg_lang]\n",
    "        #print(src_word)\n",
    "        # Initialize the start-of-word token\n",
    "        sow=0\n",
    "        \n",
    "        # Convert source and target words to lists of vocabulary indices\n",
    "        src = [self.src_vocab.get(char, self.src_vocab['<unk>']) for char in src_word]\n",
    "        trg = [self.trg_vocab.get(char, self.src_vocab['<unk>']) for char in trg_word]\n",
    "        # Insert the start-of-word token at the beginning\n",
    "        src.insert(0, sow)\n",
    "        trg.insert(0, sow)\n",
    "\n",
    "        src_len = len(src)\n",
    "        trg_len = len(trg)\n",
    "\n",
    "        # Pad the source and target sequences with the <pad> token\n",
    "        src_pad = [self.src_vocab['<pad>']] * (self.max_src_len - src_len)\n",
    "        trg_pad = [self.trg_vocab['<pad>']] * (self.max_trg_len - trg_len)\n",
    "\n",
    "        # Extend the source and target sequences with padding\n",
    "        src.extend(src_pad)\n",
    "        trg.extend(trg_pad)\n",
    "\n",
    "        # Convert source and target sequences to tensors\n",
    "        src = torch.LongTensor(src)\n",
    "        trg = torch.LongTensor(trg)\n",
    "        #trg_one_hot = self.target_to_one_hot(trg_word, self.trg_vocab)\n",
    "        #src_one_hot = self.target_to_one_hot(src_word, self.src_vocab)\n",
    "\n",
    "        # This will return encoded source word ,target word and their length\n",
    "        return src, trg, src_len, trg_len\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T10:39:10.961592Z",
     "iopub.status.busy": "2024-05-13T10:39:10.961308Z",
     "iopub.status.idle": "2024-05-13T10:39:10.974829Z",
     "shell.execute_reply": "2024-05-13T10:39:10.973810Z",
     "shell.execute_reply.started": "2024-05-13T10:39:10.961560Z"
    },
    "id": "W50h47NjF3tF",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def load_data(bs):\n",
    "    '''\n",
    "    This function loads data into batches provided the batch size as an argument.\n",
    "    '''\n",
    "    # Define the paths for the train, validation, and test CSV files\n",
    "    train_path  =\"/kaggle/input/akshrantar/aksharantar_sampled/tel/tel_train.csv\"\n",
    "    val_path  =\"/kaggle/input/akshrantar/aksharantar_sampled/tel/tel_valid.csv\"\n",
    "    test_path  =\"/kaggle/input/akshrantar/aksharantar_sampled/tel/tel_test.csv\"\n",
    "\n",
    "    # Create a vocabulary object and retrieve the source and target vocabularies,\n",
    "    # character-to-index and index-to-character mappings\n",
    "    vocab = Vocabulary(train_path, 'src', 'trg')\n",
    "    src_vocab,trg_vocab,t_char_to_idx,t_idx_to_char,s_char_to_idx,s_idx_to_char=vocab.get()\n",
    "    #print(len(src_vocab))\n",
    "    #print(len(trg_vocab))\n",
    "    #print(\"char to idc outside\",char_to_idx)\n",
    "\n",
    "\n",
    "    # Create train, validation, and test datasets using TransliterationDataset\n",
    "    # with the appropriate source and target vocabularies and mappings\n",
    "    train_dataset = TransliterationDataset(train_path, 'src', 'trg',src_vocab,trg_vocab,t_char_to_idx)\n",
    "    val_dataset = TransliterationDataset(val_path, 'src', 'trg',src_vocab,trg_vocab,t_char_to_idx)\n",
    "    test_dataset = TransliterationDataset(test_path, 'src', 'trg',src_vocab,trg_vocab,t_char_to_idx)\n",
    "    \n",
    "    # Create train, validation, and test data loaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=bs, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=bs, shuffle=False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=bs, shuffle=False)\n",
    "    \n",
    "    return train_loader,test_loader,val_loader,t_idx_to_char,s_idx_to_char\n",
    "\n",
    "\n",
    "    #Training and check accuracy function\n",
    " \n",
    "  \n",
    "#train_loader,test_loader,val_loader,idx_to_char=load_data(32)\n",
    "#print(idx_to_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T10:39:10.976511Z",
     "iopub.status.busy": "2024-05-13T10:39:10.976261Z",
     "iopub.status.idle": "2024-05-13T10:39:11.003445Z",
     "shell.execute_reply": "2024-05-13T10:39:11.002503Z",
     "shell.execute_reply.started": "2024-05-13T10:39:10.976489Z"
    },
    "id": "VpRLyDoRGCi6",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Model\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, embedded_size,hidden_dim, num_layers,bidirectional, cell_type,dp):\n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        # Store the input dimensions, embedding size, hidden size, number of layers,\n",
    "        # bidirectional flag, cell type, and dropout probability\n",
    "        self.input_dim = input_dim\n",
    "        self.embedded_size=embedded_size\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.cell_type = cell_type\n",
    "        self.bidirectional=bidirectional\n",
    "        self.dropout = nn.Dropout(dp)\n",
    "\n",
    "        # Determine the directionality of the encoder (1 for unidirectional, 2 for bidirectional)\n",
    "        if bidirectional:\n",
    "            self.dir=2\n",
    "        else:\n",
    "            self.dir=1  \n",
    "        # Create an embedding layer\n",
    "        self.embedding = nn.Embedding(input_dim,embedded_size)\n",
    "\n",
    "        # Create the recurrent layer based on the specified cell type\n",
    "        if cell_type == 'rnn':\n",
    "              self.rnn = nn.RNN(embedded_size, hidden_dim, num_layers, dropout=dp,bidirectional=bidirectional)\n",
    "        elif cell_type == 'lstm':\n",
    "              self.rnn = nn.LSTM(embedded_size, hidden_dim, num_layers, dropout=dp,bidirectional=bidirectional)\n",
    "        elif cell_type == 'gru':\n",
    "              self.rnn = nn.GRU(embedded_size, hidden_dim, num_layers, dropout=dp,bidirectional=bidirectional)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid cell type. Choose 'rnn', 'lstm', or 'gru'.\")     \n",
    "\n",
    "    def forward(self, src):\n",
    "        # Apply dropout to the embedded input\n",
    "        embedded = self.dropout(self.embedding(src))\n",
    "        # If the cell type is LSTM, return both the output and the hidden and cell states in a single tuple\n",
    "        if self.cell_type == 'lstm':\n",
    "            output, (hidden, cell) = self.rnn(embedded)\n",
    "            return output, (hidden, cell)\n",
    "\n",
    "        else:\n",
    "            # For other cell types (RNN, GRU), return the output and the hidden state\n",
    "            output, hidden = self.rnn(embedded)\n",
    "            return output,hidden\n",
    "\n",
    "\n",
    "        \n",
    "        \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim,embedded_size, hidden_dim, num_layers,bidirectional,cell_type,dp):\n",
    "        super(Decoder, self).__init__()\n",
    "        # Store the input dimensions, embedding size, hidden size, number of layers,\n",
    "        # bidirectional flag, cell type, and dropout probabilit  \n",
    "        self.output_dim = output_dim\n",
    "        self.embedded_size=embedded_size     \n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.cell_type = cell_type\n",
    "        self.bidirectional=bidirectional\n",
    "        self.dropout = nn.Dropout(dp)\n",
    "        if bidirectional:\n",
    "            self.dir=2\n",
    "        else:\n",
    "            self.dir=1  \n",
    "\n",
    "        # Create an embedding layer\n",
    "        self.embedding = nn.Embedding(output_dim,embedded_size)\n",
    "        # Create the recurrent layer based on the specified cell type\n",
    "        if cell_type == 'rnn':\n",
    "            self.rnn = nn.RNN(embedded_size, hidden_dim, num_layers,dropout=dp)\n",
    "        elif cell_type == 'lstm':\n",
    "            self.rnn = nn.LSTM(embedded_size, hidden_dim, num_layers,dropout=dp)\n",
    "        elif cell_type == 'gru':\n",
    "            self.rnn = nn.GRU(embedded_size, hidden_dim, num_layers,dropout=dp)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid cell type. Choose 'rnn', 'lstm', or 'gru'.\")\n",
    "\n",
    "        # Create the output fully connected layer\n",
    "        self.fc_out = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        # Pass the embedded input and hidden state through the decoder RNN\n",
    "        output, hidden = self.rnn(embedded, hidden)\n",
    "        # Pass the decoder output through the fully connected layer\n",
    "        output = self.fc_out(output)\n",
    "        # Apply log softmax activation to the output\n",
    "        output = F.log_softmax(output, dim=1)\n",
    "\n",
    "        return output, hidden\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder,cell_type,bidirectional):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.cell_type=cell_type\n",
    "        self.bidirectional=bidirectional\n",
    "        \n",
    "    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n",
    "        batch_size = trg.shape[1]\n",
    "        #print(batch_size)\n",
    "        max_len = trg.shape[0]\n",
    "        #print(max_len)\n",
    "        trg_vocab_size = self.decoder.output_dim\n",
    "        \n",
    "        outputs = torch.zeros(max_len, batch_size, trg_vocab_size).to(device)\n",
    "        \n",
    "        encoder_output, encoder_hidden = self.encoder(src)\n",
    "        #print(\"encoder hidden shape\",encoder_hidden.shape)\n",
    "        # Concatenate the last hidden state of the encoder from both directions\n",
    "        if self.bidirectional:\n",
    "            if self.cell_type=='lstm':\n",
    "                hidden_concat = torch.add(encoder_hidden[0][0:self.encoder.num_layers,:,:], encoder_hidden[1][0:self.encoder.num_layers,:,:])/2\n",
    "                cell_concat = torch.add(encoder_hidden[0][self.encoder.num_layers:,:,:], encoder_hidden[1][self.encoder.num_layers:,:,:])/2\n",
    "                hidden_concat = (hidden_concat, cell_concat)\n",
    "\n",
    "            else:\n",
    "                hidden_concat = torch.add(encoder_hidden[0:self.encoder.num_layers,:,:], encoder_hidden[self.encoder.num_layers:,:,:])/2\n",
    "        else:\n",
    "            hidden_concat= encoder_hidden\n",
    "        \n",
    "        decoder_hidden = hidden_concat\n",
    "        # Initialize decoder input with the start token\n",
    "        decoder_input = (trg[0,:]).unsqueeze(0)\n",
    "        #print(\"decoder input shape\",decoder_input.shape)\n",
    "        \n",
    "        for t in range(1,trg.shape[0] ):\n",
    "\n",
    "            # Pass the decoder input and hidden state through the decoder\n",
    "            decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden)\n",
    "            \n",
    "            # Store the decoder output in the outputs tensor\n",
    "            outputs[t] = decoder_output\n",
    "            # Determine the next decoder input using teacher forcing or predicted output\n",
    "            max_pr, idx=torch.max(decoder_output,dim=2)\n",
    "            #print(\"trg shape\",trg.shape)\n",
    "            idx=idx.view(trg.shape[1])\n",
    "            teacher_force = torch.rand(1) < teacher_forcing_ratio\n",
    "            if teacher_force:\n",
    "                decoder_input= trg[t,:].unsqueeze(0)\n",
    "            else:\n",
    "                decoder_input= idx.unsqueeze(0)\n",
    "\n",
    "         # Pass the last decoder input and hidden state through the decoder\n",
    "        decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden)\n",
    "        \n",
    "        # Store the final decoder output in the outputs tensor\n",
    "        #outputs[-1] = decoder_output\n",
    "        return outputs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T10:39:11.004923Z",
     "iopub.status.busy": "2024-05-13T10:39:11.004630Z",
     "iopub.status.idle": "2024-05-13T10:39:11.017355Z",
     "shell.execute_reply": "2024-05-13T10:39:11.016540Z",
     "shell.execute_reply.started": "2024-05-13T10:39:11.004898Z"
    },
    "id": "S4cPKpxWGALj",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def indices_to_string(trg, t_idx_to_char):\n",
    "    \"\"\"Converts a batch of indices to strings using the given index-to-char mapping\n",
    "    Args:\n",
    "    trg(Tensor):encoder words of size batch_size x sequence length\n",
    "    t_idx_to_char(Dict.): index to char mapping\n",
    "    \n",
    "    \"\"\"\n",
    "    strings = []\n",
    "    bs=trg.shape[0]\n",
    "    sq=trg.shape[1]\n",
    "    for i in range(bs):\n",
    "      chars = []\n",
    "      #print(i)\n",
    "      # Convert the sequence of indices to a sequence of characters using the index-to-char mapping\n",
    "      for j in range(sq):\n",
    "        #print(j)\n",
    "        #print(trg[i,j].item())            \n",
    "        if trg[i,j].item() in t_idx_to_char:\n",
    "          #print(trg[i,j])\n",
    "          char = t_idx_to_char[trg[i,j].item()]\n",
    "          chars.append(char)\n",
    "            #print(chars)\n",
    "      # Join the characters into a string\n",
    "      string = ''.join(chars)\n",
    "      #print(string)\n",
    "        # Append the string to the list of strings\n",
    "      strings.append(string)\n",
    "    return strings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T10:39:11.018675Z",
     "iopub.status.busy": "2024-05-13T10:39:11.018416Z",
     "iopub.status.idle": "2024-05-13T10:39:11.029866Z",
     "shell.execute_reply": "2024-05-13T10:39:11.029051Z",
     "shell.execute_reply.started": "2024-05-13T10:39:11.018654Z"
    },
    "id": "24EGz_7-GK74",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def calculate_word_level_accuracy(model,t_idx_to_char,data_loader, criterion):\n",
    "    model.eval()\n",
    "    num_correct = 0\n",
    "    num_total = 0\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (src, trg, src_len, trg_len) in enumerate(data_loader):\n",
    "            # Convert target indices to string for comparison\n",
    "            string_trg=indices_to_string(trg,t_idx_to_char)\n",
    "            # Move tensors to the device\n",
    "            src = src.permute(1, 0)\n",
    "            trg = trg.permute(1, 0)\n",
    "            src = src.to(device)\n",
    "            trg = trg.to(device)\n",
    "            # Perform forward pass through the model\n",
    "            output = model(src, trg, 0)\n",
    "            # turn off teacher forcing\n",
    "            output = output[1:].reshape(-1, output.shape[2])\n",
    "            #print(\"op after \",output.shape) # exclude the start-of-sequence token\n",
    "\n",
    "            trg = trg[1:].reshape(-1) # exclude the start-of-sequence token\n",
    "            #print(\"trg after reshape\",trg.shape)\n",
    "            \n",
    "            # Calculate the loss\n",
    "            output = output.to(device)\n",
    "            loss = criterion(output, trg)\n",
    "            epoch_loss += loss.item()\n",
    "            \n",
    "            batch_size = trg_len.shape[0]\n",
    "            #print(\"bs\", batch_size)\n",
    "            seq_length = int(trg.numel() / batch_size)\n",
    "            \n",
    "\n",
    "            # Convert the output to predicted characters\n",
    "            predicted_indices = torch.argmax(output, dim=1)\n",
    "            predicted_indices = predicted_indices.reshape(seq_length,-1)\n",
    "            predicted_indices = predicted_indices.permute(1, 0)\n",
    "            # Convert predicted indices to strings\n",
    "            string_pred=indices_to_string(predicted_indices,t_idx_to_char)\n",
    "            #print(string_pred)\n",
    "            #print(string_trg)\n",
    "            \n",
    "            for i in range(batch_size):\n",
    "                num_total+=1\n",
    "                # Compare the predicted string with the target string\n",
    "                if string_pred[i][:len(string_trg[i])] == string_trg[i]:\n",
    "                    num_correct+=1\n",
    "\n",
    "    print(\"Total\",num_total)\n",
    "    print(\"Correct\",num_correct)\n",
    "    # Calculate word-level accuracy and average loss\n",
    "    return (num_correct /num_total) * 100, (epoch_loss/(len(data_loader)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T10:39:11.031863Z",
     "iopub.status.busy": "2024-05-13T10:39:11.031283Z",
     "iopub.status.idle": "2024-05-13T10:39:11.046279Z",
     "shell.execute_reply": "2024-05-13T10:39:11.045459Z",
     "shell.execute_reply.started": "2024-05-13T10:39:11.031832Z"
    },
    "id": "7TTpm6ZXhyiw",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def calculate_word_level_accuracy1(model,t_idx_to_char,s_idx_to_char,data_loader, criterion):\n",
    "    model.eval()\n",
    "    num_correct = 0\n",
    "    num_total = 0\n",
    "    epoch_loss = 0\n",
    "    c_trg=[]\n",
    "    c_src=[]\n",
    "    c_pred=[]\n",
    "    \n",
    "    i_trg=[]\n",
    "    i_src=[]\n",
    "    i_pred=[]\n",
    "    \n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (src, trg, src_len, trg_len) in enumerate(data_loader):\n",
    "            # Convert target indices to string for comparison\n",
    "            string_trg=indices_to_string(trg,t_idx_to_char)\n",
    "            string_src=indices_to_string(src,s_idx_to_char)\n",
    "            \n",
    "            # Move tensors to the device\n",
    "            src = src.permute(1, 0)\n",
    "            trg = trg.permute(1, 0)\n",
    "            src = src.to(device)\n",
    "            trg = trg.to(device)\n",
    "            # Perform forward pass through the model\n",
    "            output = model(src, trg, 0)\n",
    "            # turn off teacher forcing\n",
    "            output = output[1:].reshape(-1, output.shape[2])\n",
    "            #print(\"op after \",output.shape) # exclude the start-of-sequence token\n",
    "\n",
    "            trg = trg[1:].reshape(-1) # exclude the start-of-sequence token\n",
    "            #print(\"trg after reshape\",trg.shape)\n",
    "            \n",
    "            # Calculate the loss\n",
    "            output = output.to(device)\n",
    "            loss = criterion(output, trg)\n",
    "            epoch_loss += loss.item()\n",
    "            \n",
    "            batch_size = trg_len.shape[0]\n",
    "            #print(\"bs\", batch_size)\n",
    "            seq_length = int(trg.numel() / batch_size)\n",
    "            \n",
    "\n",
    "            # Convert the output to predicted characters\n",
    "            predicted_indices = torch.argmax(output, dim=1)\n",
    "            predicted_indices = predicted_indices.reshape(seq_length,-1)\n",
    "            predicted_indices = predicted_indices.permute(1, 0)\n",
    "            # Convert predicted indices to strings\n",
    "            string_pred=indices_to_string(predicted_indices,t_idx_to_char)\n",
    "            #print(string_pred)\n",
    "            #print(string_trg)\n",
    "            \n",
    "            for i in range(batch_size):\n",
    "                num_total+=1\n",
    "                # Compare the predicted string with the target string\n",
    "                if string_pred[i][:len(string_trg[i])] == string_trg[i]:\n",
    "                  c_trg.append(string_trg[i])\n",
    "                  c_src.append(string_src[i])\n",
    "                  c_pred.append(string_pred[i][:len(string_trg[i])])\n",
    "                  num_correct+=1\n",
    "                else :\n",
    "                  i_trg.append(string_trg[i])\n",
    "                  i_src.append(string_src[i])\n",
    "                  i_pred.append(string_pred[i][:len(string_trg[i])])\n",
    "                  \n",
    "\n",
    "\n",
    "    print(\"Total\",num_total)\n",
    "    print(\"Correct\",num_correct)\n",
    "    # Calculate word-level accuracy and average loss\n",
    "    return (num_correct /num_total) * 100, (epoch_loss/(len(data_loader))),c_trg,c_src,c_pred,i_trg,i_src,i_pred\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-05-13T11:25:33.845071Z",
     "iopub.status.busy": "2024-05-13T11:25:33.844252Z",
     "iopub.status.idle": "2024-05-13T11:30:19.222210Z",
     "shell.execute_reply": "2024-05-13T11:30:19.221129Z",
     "shell.execute_reply.started": "2024-05-13T11:25:33.845042Z"
    },
    "id": "1ttOezGyGOgF",
    "outputId": "09c85988-7e54-405f-8484-4d8c7292808a",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Batch: 0, Training...\n",
      "Total 4096\n",
      "Correct 2368\n",
      "Epoch: 0, Loss: 0.11377724396064877, Val Acc: 57.8125, Val loss: 0.3796164346858859\n",
      "Epoch: 1, Batch: 0, Training...\n",
      "Total 4096\n",
      "Correct 2373\n",
      "Epoch: 1, Loss: 0.11050638578832149, Val Acc: 57.9345703125, Val loss: 0.37694042501971126\n",
      "Epoch: 2, Batch: 0, Training...\n",
      "Total 4096\n",
      "Correct 2360\n",
      "Epoch: 2, Loss: 0.10974751249887049, Val Acc: 57.6171875, Val loss: 0.37962538795545697\n",
      "Epoch: 3, Batch: 0, Training...\n",
      "Total 4096\n",
      "Correct 2367\n",
      "Epoch: 3, Loss: 0.10416975738480687, Val Acc: 57.7880859375, Val loss: 0.381745089776814\n",
      "Epoch: 4, Batch: 0, Training...\n",
      "Total 4096\n",
      "Correct 2376\n",
      "Epoch: 4, Loss: 0.10358073063194752, Val Acc: 58.0078125, Val loss: 0.3780182609334588\n",
      "Best model saved to best_model_vanillaSeq2Seq.pth\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define hyperparameters\n",
    "INPUT_DIM = 29\n",
    "OUTPUT_DIM = 67\n",
    "embedding_size=256\n",
    "HIDDEN_DIM = 512\n",
    "NUM_LAYERS = 4\n",
    "CELL_TYPE = 'lstm'\n",
    "BATCH_SIZE = 128\n",
    "LEARNING_RATE = 0.0001\n",
    "TEACHER_FORCING_RATIO = 0.1\n",
    "EPOCHS = 5\n",
    "\n",
    "dropout=0.2\n",
    "bidirectional=False\n",
    "opt='nadam'\n",
    "\n",
    "# Load data and create data loaders\n",
    "train_loader,test_loader,val_loader,t_idx_to_char,s_idx_to_char=load_data(BATCH_SIZE)\n",
    "#print(len(test_loader))\n",
    "#print(len(train_loader))\n",
    "#print(len(val_loader))\n",
    "# Instantiate the Encoder and Decoder models\n",
    "encoder = Encoder(INPUT_DIM,embedding_size,HIDDEN_DIM, NUM_LAYERS,bidirectional, CELL_TYPE,dropout).to(device)\n",
    "decoder = Decoder(OUTPUT_DIM,embedding_size,HIDDEN_DIM, NUM_LAYERS,bidirectional,CELL_TYPE,dropout).to(device)\n",
    "\n",
    "# Instantiate the Seq2Seq model with the Encoder and Decoder models\n",
    "# model = Seq2Seq(encoder, decoder,CELL_TYPE,bidirectional).to(device)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "#optimizer=optimizer(model,opt,LEARNING_RATE)\n",
    "# Train the model\n",
    "for epoch in range(EPOCHS):\n",
    "    epoch_loss = 0\n",
    "    model.train()\n",
    "\n",
    "    for batch_idx, (src, trg, src_len, trg_len) in enumerate(train_loader):\n",
    "        #print(batch_idx)\n",
    "        src = src.permute(1, 0)  # swapping the dimensions of src tensor\n",
    "        trg = trg.permute(1, 0)  # swapping the dimensions of trg tensor\n",
    "\n",
    "        src = src.to(device)\n",
    "        trg = trg.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(src, trg, TEACHER_FORCING_RATIO)\n",
    "        \n",
    "        # Ignore the first element of the output, which is initialized as all zeros\n",
    "        # since we use it to store the output for the start-of-sequence token\n",
    "        #print(output.shape[2])\n",
    "        \n",
    "        output = output[1:].reshape(-1, output.shape[2])\n",
    "        #print(output.shape)\n",
    "        #print(trg.shape)\n",
    "        trg = trg[1:].reshape(-1)\n",
    "        \n",
    "        loss = criterion(output, trg)\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += (loss.item())\n",
    "        \n",
    "        if batch_idx % 1000 == 0:\n",
    "            print(f\"Epoch: {epoch}, Batch: {batch_idx}, Training...\")\n",
    "\n",
    "    # Calculate word-level accuracy after every epoch\n",
    "    val_acc,val_loss = calculate_word_level_accuracy(model,t_idx_to_char,val_loader,criterion)\n",
    "    \n",
    "    print(f\"Epoch: {epoch}, Loss: {epoch_loss / (len(train_loader))}, Val Acc: {val_acc}, Val loss: {val_loss}\")\n",
    "    #wandb.log({'epoch': epoch, 'loss': loss.item(), 'test_acc': test_acc,'train_acc': train_acc,'val_acc': val_acc})\n",
    "    \n",
    "   \n",
    "# Save best model\n",
    "best_model_path = 'best_model_vanillaSeq2Seq.pth'\n",
    "torch.save(model.state_dict(), best_model_path)\n",
    "print(f\"Best model saved to {best_model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-05-13T11:30:43.284902Z",
     "iopub.status.busy": "2024-05-13T11:30:43.284069Z",
     "iopub.status.idle": "2024-05-13T11:30:48.776811Z",
     "shell.execute_reply": "2024-05-13T11:30:48.775852Z",
     "shell.execute_reply.started": "2024-05-13T11:30:43.284870Z"
    },
    "id": "pc8CgAudsUZw",
    "outputId": "d599ea80-7d7e-444f-a386-3e2070f10d4b",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 4096\n",
      "Correct 2189\n"
     ]
    }
   ],
   "source": [
    "val_acc,val_loss,c_trg,c_src,c_pred,i_trg,i_src,i_pred = calculate_word_level_accuracy1(model,t_idx_to_char,s_idx_to_char,test_loader,criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-13T11:30:48.778554Z",
     "iopub.status.busy": "2024-05-13T11:30:48.778275Z",
     "iopub.status.idle": "2024-05-13T11:30:48.784164Z",
     "shell.execute_reply": "2024-05-13T11:30:48.783230Z",
     "shell.execute_reply.started": "2024-05-13T11:30:48.778530Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53.4423828125"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-05-13T11:31:02.057715Z",
     "iopub.status.busy": "2024-05-13T11:31:02.057004Z",
     "iopub.status.idle": "2024-05-13T11:31:02.073224Z",
     "shell.execute_reply": "2024-05-13T11:31:02.072095Z",
     "shell.execute_reply.started": "2024-05-13T11:31:02.057682Z"
    },
    "id": "pbOnZb9bsYEn",
    "outputId": "38944665-44d4-46c4-feb3-9d4e503ea682",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# print(c_trg)\n",
    "# print(c_src)\n",
    "# print(c_pred)\n",
    "import csv\n",
    "def save_to_csv(src_list, trg_list, pred_list, file_name):\n",
    "    rows = zip(src_list, trg_list, pred_list)\n",
    "\n",
    "    with open(file_name, mode='w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(['Source', 'Target', 'Predicted'])\n",
    "        writer.writerows(rows)\n",
    "\n",
    "save_to_csv(c_src,c_trg,c_pred,'AttenSeq2Seq_correct_data_predictions.csv')\n",
    "save_to_csv(i_src,i_trg,i_pred,'AttenSeq2Seq_incorrect_data_predictions.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-04T08:16:42.771967Z",
     "iopub.status.busy": "2024-05-04T08:16:42.771296Z",
     "iopub.status.idle": "2024-05-04T08:16:42.784823Z",
     "shell.execute_reply": "2024-05-04T08:16:42.783884Z",
     "shell.execute_reply.started": "2024-05-04T08:16:42.771934Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# x = pd.read_csv(\"/kaggle/working/incorrect_predictions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-05-12T02:52:41.557044Z",
     "iopub.status.busy": "2024-05-12T02:52:41.556695Z",
     "iopub.status.idle": "2024-05-12T02:53:05.447669Z",
     "shell.execute_reply": "2024-05-12T02:53:05.446562Z",
     "shell.execute_reply.started": "2024-05-12T02:52:41.557017Z"
    },
    "id": "hjo4OyZ3UyZa",
    "outputId": "899d03f2-1eb0-412d-c2d3-370c9ee16e10",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    }
   ],
   "source": [
    "from signal import signal,SIGPIPE, SIG_DFL\n",
    "signal(SIGPIPE,SIG_DFL)\n",
    "!pip install wandb -qU\n",
    "import wandb\n",
    "!wandb login "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "id": "blBCql1puVLK",
    "outputId": "2238ad37-c1ad-4fe9-fe64-ace7ce8f4f7c",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# # Load the CSV file\n",
    "# import pandas as pd\n",
    "# c_dataframe = pd.read_csv(\"/content/correct_predictions.csv\")\n",
    "# table = wandb.Table(dataframe=c_dataframe)\n",
    "\n",
    "# # Add the table to an Artifact to increase the row \n",
    "# # limit to 200000 and make it easier to reuse\n",
    "# c_table_artifact = wandb.Artifact(\n",
    "#     \"correct_predictions_vanilla\", \n",
    "#     type=\"dataset\"\n",
    "#     )        \n",
    "# c_table_artifact.add(table, \"Correct_predictions\")\n",
    "\n",
    "# # Log the raw csv file within an artifact to preserve our data\n",
    "# c_table_artifact.add_file(\"/content/correct_predictions.csv\")\n",
    "\n",
    "# # Display as a table\n",
    "\n",
    "\n",
    "# run = wandb.init(project='CS6910_Assignment3')\n",
    "\n",
    "# # Log the table to visualize with a run...\n",
    "# run.log({\"Vanilla_correct_predictions_table\": table})\n",
    "\n",
    "# # and Log as an Artifact to increase the available row limit!\n",
    "# run.log_artifact(c_table_artifact)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 227
    },
    "execution": {
     "iopub.status.busy": "2024-05-01T10:41:15.186939Z",
     "iopub.status.idle": "2024-05-01T10:41:15.187328Z",
     "shell.execute_reply": "2024-05-01T10:41:15.187160Z",
     "shell.execute_reply.started": "2024-05-01T10:41:15.187143Z"
    },
    "id": "obnBUXicxH98",
    "outputId": "1c88f798-a9c3-4714-ec7d-d8a0f30555be",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# # Load the CSV file\n",
    "# i_dataframe = pd.read_csv(\"/content/incorrect_predictions.csv\")\n",
    "# i_table = wandb.Table(dataframe=i_dataframe)\n",
    "\n",
    "# # Add the table to an Artifact to increase the row \n",
    "# # limit to 200000 and make it easier to reuse\n",
    "# i_table_artifact = wandb.Artifact(\n",
    "#     \"incorrect_predictions_vanilla\", \n",
    "#     type=\"dataset\"\n",
    "#     )        \n",
    "# i_table_artifact.add(i_table, \"Incorrect_predictions\")\n",
    "\n",
    "# # Log the raw csv file within an artifact to preserve our data\n",
    "# i_table_artifact.add_file(\"/content/incorrect_predictions.csv\")\n",
    "\n",
    "# # Display as a table\n",
    "\n",
    "\n",
    "# run = wandb.init(project='\"CS6910_Assignment3\"')\n",
    "\n",
    "# # Log the table to visualize with a run...\n",
    "# run.log({\"Vanilla_incorrect_predictions_table\": i_table})\n",
    "\n",
    "# # and Log as an Artifact to increase the available row limit!\n",
    "# run.log_artifact(i_table_artifact)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-12T02:53:26.692652Z",
     "iopub.status.busy": "2024-05-12T02:53:26.691831Z",
     "iopub.status.idle": "2024-05-12T02:53:26.713942Z",
     "shell.execute_reply": "2024-05-12T02:53:26.713035Z",
     "shell.execute_reply.started": "2024-05-12T02:53:26.692614Z"
    },
    "id": "h9lJPg3DjBkT",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# wandb sweeps\n",
    "\n",
    "sweep_config= {\n",
    "    \"name\" : \"Seq2Seq\",\n",
    "    \"method\" : \"bayes\",\n",
    "    'metric': {\n",
    "        'name': 'validation_accuracy',\n",
    "        'goal': 'maximize'\n",
    "    },\n",
    "    'parameters' : {\n",
    "        'cell_type' : { 'values' : ['lstm','gru','rnn'] },\n",
    "        'dropout' : { 'values' : [0,0.1,0.2,0.5]},\n",
    "        'embedding_size' : {'values' : [64,128,256,512]},\n",
    "        'num_layers' : {'values' : [2, 3, 4]},\n",
    "        'batch_size' : {'values' : [32,64,128]},\n",
    "        'hidden_size' : {'values' : [128,256,512]},\n",
    "        'bidirectional' : {'values' : [True ,False]},\n",
    "        'learning_rate':{\n",
    "            \"values\": [0.001,0.002,0.0001,0.0002]\n",
    "        },\n",
    "        'epochs': {\n",
    "            'values': [15, 20, 25]\n",
    "        },\n",
    "        'optim':{\n",
    "            \"values\": ['adam','nadam']\n",
    "        },\n",
    "        'teacher_forcing':{\"values\":[0.2,0.5,0.7]}\n",
    "    }\n",
    "}\n",
    "# sweep_config= {\n",
    "#     \"name\" : \"Seq2Seq_Attn2\",\n",
    "#     \"method\" : \"bayes\",\n",
    "#     'metric': {\n",
    "#         'name': 'validation_accuracy',\n",
    "#         'goal': 'maximize'\n",
    "#     },\n",
    "#     'parameters' : {\n",
    "#         'cell_type' : { 'values' : ['lstm','gru'] },\n",
    "#         'dropout' : { 'values' : [0,0.1,0.2,0.5]},\n",
    "#         'embedding_size' : {'values' : [128,256,512]},\n",
    "#         'num_layers' : {'values' : [3, 4]},\n",
    "#         'batch_size' : {'values' : [32,64,128]},\n",
    "#         'hidden_size' : {'values' : [128,256,512]},\n",
    "#         'bidirectional' : {'values' : [True ,False]},\n",
    "#         'learning_rate':{\n",
    "#             \"values\": [0.001,0.002]\n",
    "#         },\n",
    "#         'epochs': {\n",
    "#             'values': [20, 25]\n",
    "#         },\n",
    "#         'optim':{\n",
    "#             \"values\": ['adam','nadam']\n",
    "#         },\n",
    "#         'teacher_forcing':{\"values\":[0.2,0.5,0.7]}\n",
    "#     }\n",
    "# }\n",
    "\n",
    "\n",
    "\n",
    "def train():\n",
    "    wandb.init()\n",
    "\n",
    "    c= wandb.config\n",
    "    name = str(c.cell_type)+\"_\"+str(c.num_layers)+\"_dropout_\"+str(c.dropout)+\"_tf_\"+str(c.teacher_forcing)+\"_lr_\"+str(c.learning_rate)+\"_bidir_\"+str(c.bidirectional)+\"_bs_\"+str(c.batch_size)\n",
    "    wandb.run.name=name\n",
    "  \n",
    "    # Retrieve the hyperparameters from the config\n",
    "    ct=c.cell_type\n",
    "    dp = c.dropout\n",
    "    em=c.embedding_size\n",
    "    nlayer=c.num_layers\n",
    "    bs = c.batch_size\n",
    "    hs=c.hidden_size\n",
    "    bidir = c.bidirectional\n",
    "    lr = c.learning_rate\n",
    "    opt= c.optim\n",
    "    epochs = c.epochs\n",
    "    tf=c.teacher_forcing\n",
    "    trg_pad_idx=0\n",
    "\n",
    "  \n",
    "\n",
    "    INPUT_DIM = 29\n",
    "    OUTPUT_DIM = 67\n",
    "\n",
    "  \n",
    "  # Load the dataset\n",
    "    train_loader,test_loader,val_loader,t_idx_to_char,s_idx_to_char=load_data(bs)\n",
    "   \n",
    "  #print(\"data loaded ====================================================\")\n",
    "\n",
    "  # Instantiate the Encoder and Decoder models\n",
    "    encoder = Encoder(INPUT_DIM,em,hs,nlayer,False,ct,dp).to(device)\n",
    "    decoder = Decoder(OUTPUT_DIM,em,hs,nlayer,False,ct,dp).to(device)\n",
    "\n",
    "  # Instantiate the Seq2Seq model with the Encoder and Decoder models\n",
    "    model = Seq2Seq(encoder,decoder,ct,False).to(device)\n",
    "  #print(\"model ini==============================================================\")\n",
    " \n",
    "  # Define the loss function and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()      \n",
    "    if opt == \"adam\":\n",
    "          optimizer = optim.Adam(model.parameters(),lr=lr)\n",
    "    elif opt == \"nadam\":\n",
    "          optimizer= optim.NAdam(model.parameters(),lr=lr)\n",
    "  \n",
    "  # Train Network\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0\n",
    "        model.train()\n",
    "\n",
    "        for batch_idx, (src, trg, src_len, trg_len) in enumerate(train_loader):\n",
    "            src = src.permute(1, 0)  # swapping the dimensions of src tensor\n",
    "            trg = trg.permute(1, 0)  # swapping the dimensions of trg tensor\n",
    "\n",
    "            src = src.to(device)\n",
    "            trg = trg.to(device)\n",
    "            #print(\"done\")\n",
    "            optimizer.zero_grad()\n",
    "            #print(\"doe\")\n",
    "            output = model(src,trg,tf)\n",
    "            #print(\"doe\")\n",
    "\n",
    "            # Ignore the first element of the output, which is initialized as all zeros\n",
    "            # since we use it to store the output for the start-of-sequence token\n",
    "            #print(output.shape[2])\n",
    "\n",
    "            output = output[1:].reshape(-1, output.shape[2])\n",
    "            #print(output.shape)\n",
    "            #print(trg.shape)\n",
    "            trg = trg[1:].reshape(-1)\n",
    "\n",
    "            loss = criterion(output, trg)\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "            if batch_idx % 1000 == 0:\n",
    "                print(f\"Epoch: {epoch}, Batch: {batch_idx} , Training..\")\n",
    "        \n",
    "        # Calculate word-level accuracy after every epoch\n",
    "        train_acc ,train_loss= calculate_word_level_accuracy(model,t_idx_to_char, train_loader,criterion)\n",
    "        val_acc,val_loss = calculate_word_level_accuracy(model,t_idx_to_char, val_loader, criterion)\n",
    "   \n",
    "        print(f\"Epoch: {epoch}, Loss: {epoch_loss / len(train_loader)}, Train Acc: {train_acc}, Val Acc: {val_acc}\")\n",
    "    # Log the metrics to WandB\n",
    "        wandb.log({'epoch': epochs, 'train_loss': train_loss, 'train_accuracy': train_acc,'validation_accuracy': val_acc,'validation_loss': val_loss})\n",
    "    # Save the best model\n",
    "    wandb.run.save()\n",
    "    wandb.run.finish()\n",
    "    return\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lhJ1jFFCjBxT",
    "outputId": "3f9fb3fa-bbe5-4149-9cfd-aa74db77419f",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# final train\n",
    "# Initialize the WandB sweep\n",
    "sweep_id = wandb.sweep(sweep_config, project='Assignment 3')\n",
    "wandb.agent(sweep_id, function=train,count=40)\n",
    "# wandb.agent(\"v2pwk205\", function=train,count=100)\n",
    "#wandb.agent(sweep_id, function=train,count=10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-05T10:29:27.984177Z",
     "iopub.status.busy": "2024-05-05T10:29:27.983789Z",
     "iopub.status.idle": "2024-05-05T10:29:27.997466Z",
     "shell.execute_reply": "2024-05-05T10:29:27.996177Z",
     "shell.execute_reply.started": "2024-05-05T10:29:27.984150Z"
    },
    "id": "ivKTzXOlGmzi",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "gpuClass": "standard",
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 4814357,
     "sourceId": 8142521,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30699,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
